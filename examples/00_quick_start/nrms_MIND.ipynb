{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NRMS: Neural News Recommendation with Multi-Head Self-Attention\n",
    "NRMS \\[1\\] is a neural news recommendation approach with multi-head selfattention. The core of NRMS is a news encoder and a user encoder. In the newsencoder, a multi-head self-attentions is used to learn news representations from news titles by modeling the interactions between words. In the user encoder, we learn representations of users from their browsed news and use multihead self-attention to capture the relatedness between the news. Besides, we apply additive\n",
    "attention to learn more informative news and user representations by selecting important words and news.\n",
    "\n",
    "## Properties of NRMS:\n",
    "- NRMS is a content-based neural news recommendation approach.\n",
    "- It uses multi-self attention to learn news representations by modeling the iteractions between words and learn user representations by capturing the relationship between user browsed news.\n",
    "- NRMS uses additive attentions to learn informative news and user representations by selecting important words and news.\n",
    "\n",
    "## Data format:\n",
    "For quicker training and evaluaiton, we sample MINDdemo dataset of 5k users from [MIND small dataset](https://msnews.github.io/). The MINDdemo dataset has the same file format as MINDsmall and MINDlarge. If you want to try experiments on MINDsmall and MINDlarge, please change the dowload source. Select the MIND_type parameter from ['large', 'small', 'demo'] to choose dataset.\n",
    " \n",
    "**MINDdemo_train** is used for training, and **MINDdemo_dev** is used for evaluation. Training data and evaluation data are composed of a news file and a behaviors file. You can find more detailed data description in [MIND repo](https://github.com/msnews/msnews.github.io/blob/master/assets/doc/introduction.md)\n",
    "\n",
    "### news data\n",
    "This file contains news information including newsid, category, subcatgory, news title, news abstarct, news url and entities in news title, entities in news abstarct.\n",
    "One simple example: <br>\n",
    "\n",
    "`N46466\tlifestyle\tlifestyleroyals\tThe Brands Queen Elizabeth, Prince Charles, and Prince Philip Swear By\tShop the notebooks, jackets, and more that the royals can't live without.\thttps://www.msn.com/en-us/lifestyle/lifestyleroyals/the-brands-queen-elizabeth,-prince-charles,-and-prince-philip-swear-by/ss-AAGH0ET?ocid=chopendata\t[{\"Label\": \"Prince Philip, Duke of Edinburgh\", \"Type\": \"P\", \"WikidataId\": \"Q80976\", \"Confidence\": 1.0, \"OccurrenceOffsets\": [48], \"SurfaceForms\": [\"Prince Philip\"]}, {\"Label\": \"Charles, Prince of Wales\", \"Type\": \"P\", \"WikidataId\": \"Q43274\", \"Confidence\": 1.0, \"OccurrenceOffsets\": [28], \"SurfaceForms\": [\"Prince Charles\"]}, {\"Label\": \"Elizabeth II\", \"Type\": \"P\", \"WikidataId\": \"Q9682\", \"Confidence\": 0.97, \"OccurrenceOffsets\": [11], \"SurfaceForms\": [\"Queen Elizabeth\"]}]\t[]`\n",
    "<br>\n",
    "\n",
    "In general, each line in data file represents information of one piece of news: <br>\n",
    "\n",
    "`[News ID] [Category] [Subcategory] [News Title] [News Abstrct] [News Url] [Entities in News Title] [Entities in News Abstract] ...`\n",
    "\n",
    "<br>\n",
    "\n",
    "We generate a word_dict file to transform words in news title to word indexes, and a embedding matrix is initted from pretrained glove embeddings.\n",
    "\n",
    "### behaviors data\n",
    "One simple example: <br>\n",
    "`1\tU82271\t11/11/2019 3:28:58 PM\tN3130 N11621 N12917 N4574 N12140 N9748\tN13390-0 N7180-0 N20785-0 N6937-0 N15776-0 N25810-0 N20820-0 N6885-0 N27294-0 N18835-0 N16945-0 N7410-0 N23967-0 N22679-0 N20532-0 N26651-0 N22078-0 N4098-0 N16473-0 N13841-0 N15660-0 N25787-0 N2315-0 N1615-0 N9087-0 N23880-0 N3600-0 N24479-0 N22882-0 N26308-0 N13594-0 N2220-0 N28356-0 N17083-0 N21415-0 N18671-0 N9440-0 N17759-0 N10861-0 N21830-0 N8064-0 N5675-0 N15037-0 N26154-0 N15368-1 N481-0 N3256-0 N20663-0 N23940-0 N7654-0 N10729-0 N7090-0 N23596-0 N15901-0 N16348-0 N13645-0 N8124-0 N20094-0 N27774-0 N23011-0 N14832-0 N15971-0 N27729-0 N2167-0 N11186-0 N18390-0 N21328-0 N10992-0 N20122-0 N1958-0 N2004-0 N26156-0 N17632-0 N26146-0 N17322-0 N18403-0 N17397-0 N18215-0 N14475-0 N9781-0 N17958-0 N3370-0 N1127-0 N15525-0 N12657-0 N10537-0 N18224-0`\n",
    "<br>\n",
    "\n",
    "In general, each line in data file represents one instance of an impression. The format is like: <br>\n",
    "\n",
    "`[Impression ID] [User ID] [Impression Time] [User Click History] [Impression News]`\n",
    "\n",
    "<br>\n",
    "\n",
    "User Click History is the user historical clicked news before Impression Time. Impression News is the displayed news in an impression, which format is:<br>\n",
    "\n",
    "`[News ID 1]-[label1] ... [News ID n]-[labeln]`\n",
    "\n",
    "<br>\n",
    "Label represents whether the news is clicked by the user. All information of news in User Click History and Impression News can be found in news data file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global settings and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-05T18:04:41.257068Z",
     "end_time": "2023-04-05T18:04:41.260850Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install scrapbook\n",
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T13:06:30.564695Z",
     "end_time": "2023-04-13T13:06:33.318706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.9.16 | packaged by conda-forge | (main, Feb  1 2023, 21:38:11) \n",
      "[Clang 14.0.6 ]\n",
      "Tensorflow version: 2.12.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "import scrapbook as sb\n",
    "from tempfile import TemporaryDirectory\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR') # only show error messages\n",
    "\n",
    "from recommenders.models.deeprec.deeprec_utils import download_deeprec_resources \n",
    "from recommenders.models.newsrec.newsrec_utils import prepare_hparams\n",
    "from recommenders.models.newsrec.models.nrms import NRMSModel\n",
    "from recommenders.models.newsrec.io.mind_iterator import MINDIterator\n",
    "from recommenders.models.newsrec.newsrec_utils import get_mind_data_set\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Tensorflow version: {}\".format(tf.__version__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T13:06:36.051434Z",
     "end_time": "2023-04-13T13:06:36.058817Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ],
    "ExecuteTime": {
     "start_time": "2023-04-13T13:06:38.718641Z",
     "end_time": "2023-04-13T13:06:38.723412Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "seed = 42\n",
    "batch_size = 32\n",
    "\n",
    "# Options: demo, small, large\n",
    "MIND_type = 'demo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-13T13:06:40.107384Z",
     "end_time": "2023-04-13T13:06:40.115491Z"
    }
   },
   "outputs": [],
   "source": [
    "tmpdir = TemporaryDirectory()\n",
    "data_path = '/Users/fennng/Documents/phd/jupiter/nrms'\n",
    "\n",
    "train_news_file = os.path.join(data_path, 'train', r'news.tsv')\n",
    "train_behaviors_file = os.path.join(data_path, 'train', r'behaviors.tsv')\n",
    "valid_news_file = os.path.join(data_path, 'valid', r'news.tsv')\n",
    "valid_behaviors_file = os.path.join(data_path, 'valid', r'behaviors.tsv')\n",
    "wordEmb_file = os.path.join(data_path, \"utils\", \"embedding.npy\")\n",
    "userDict_file = os.path.join(data_path, \"utils\", \"uid2index.pkl\")\n",
    "wordDict_file = os.path.join(data_path, \"utils\", \"word_dict.pkl\")\n",
    "yaml_file = os.path.join(data_path, \"utils\", r'nrms.yaml')\n",
    "\n",
    "mind_url, mind_train_dataset, mind_dev_dataset, mind_utils = get_mind_data_set(MIND_type)\n",
    "\n",
    "if not os.path.exists(train_news_file):\n",
    "    download_deeprec_resources(mind_url, os.path.join(data_path, 'train'), mind_train_dataset)\n",
    "    \n",
    "if not os.path.exists(valid_news_file):\n",
    "    download_deeprec_resources(mind_url, \\\n",
    "                               os.path.join(data_path, 'valid'), mind_dev_dataset)\n",
    "if not os.path.exists(yaml_file):\n",
    "    download_deeprec_resources(r'https://recodatasets.z20.web.core.windows.net/newsrec/', \\\n",
    "                               os.path.join(data_path, 'utils'), mind_utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-13T13:06:41.455737Z",
     "end_time": "2023-04-13T13:06:41.460781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HParams object with values {'support_quick_scoring': True, 'dropout': 0.2, 'attention_hidden_dim': 200, 'head_num': 20, 'head_dim': 20, 'filter_num': 200, 'window_size': 3, 'vert_emb_dim': 100, 'subvert_emb_dim': 100, 'gru_unit': 400, 'type': 'ini', 'user_emb_dim': 50, 'learning_rate': 0.0001, 'optimizer': 'adam', 'epochs': 5, 'batch_size': 32, 'show_step': 10, 'title_size': 30, 'his_size': 50, 'data_format': 'news', 'npratio': 4, 'metrics': ['group_auc', 'mean_mrr', 'ndcg@5;10'], 'word_emb_dim': 300, 'model_type': 'nrms', 'loss': 'cross_entropy_loss', 'wordEmb_file': '/Users/fennng/Documents/phd/jupiter/nrms/utils/embedding.npy', 'wordDict_file': '/Users/fennng/Documents/phd/jupiter/nrms/utils/word_dict.pkl', 'userDict_file': '/Users/fennng/Documents/phd/jupiter/nrms/utils/uid2index.pkl'}\n"
     ]
    }
   ],
   "source": [
    "hparams = prepare_hparams(yaml_file, \n",
    "                          wordEmb_file=wordEmb_file,\n",
    "                          wordDict_file=wordDict_file, \n",
    "                          userDict_file=userDict_file,\n",
    "                          batch_size=batch_size,\n",
    "                          epochs=epochs,\n",
    "                          show_step=10)\n",
    "print(hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the NRMS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-13T13:06:42.835136Z",
     "end_time": "2023-04-13T13:06:42.839847Z"
    }
   },
   "outputs": [],
   "source": [
    "iterator = MINDIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "start_time": "2023-04-13T13:06:43.759232Z",
     "end_time": "2023-04-13T13:06:44.891865Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 13:06:44.111684: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-04-13 13:06:44.115075: W tensorflow/c/c_api.cc:300] Operation '{name:'embedding/embeddings/Assign' id:26 op device:{requested: '', assigned: ''} def:{{{node embedding/embeddings/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](embedding/embeddings, embedding/embeddings/Initializer/stateless_random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/Users/fennng/mambaforge/envs/reco_base/lib/python3.9/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = NRMSModel(hparams, iterator, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-05T18:18:59.048732Z",
     "end_time": "2023-04-05T18:20:19.929776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/fennng/mambaforge/envs/reco_base/lib/python3.9/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-04-13 13:06:55.152176: W tensorflow/c/c_api.cc:300] Operation '{name:'att_layer2_1/b/Assign' id:803 op device:{requested: '', assigned: ''} def:{{{node att_layer2_1/b/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](att_layer2_1/b, att_layer2_1/b/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "586it [00:03, 157.94it/s]\n",
      "0it [00:00, ?it/s]2023-04-13 13:06:58.807225: W tensorflow/c/c_api.cc:300] Operation '{name:'att_layer2_1/Sum_1' id:864 op device:{requested: '', assigned: ''} def:{{{node att_layer2_1/Sum_1}} = Sum[T=DT_FLOAT, Tidx=DT_INT32, _has_manual_control_dependencies=true, keep_dims=false](att_layer2_1/mul, att_layer2_1/Sum_1/reduction_indices)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "60it [00:12,  4.75it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhi\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_eval\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalid_news_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid_behaviors_file\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/gitLocal/recommenders/recommenders/models/newsrec/models/base_model.py:328\u001B[0m, in \u001B[0;36mBaseModel.run_eval\u001B[0;34m(self, news_filename, behaviors_file)\u001B[0m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;124;03m\"\"\"Evaluate the given file and returns some evaluation metrics.\u001B[39;00m\n\u001B[1;32m    319\u001B[0m \n\u001B[1;32m    320\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    324\u001B[0m \u001B[38;5;124;03m    dict: A dictionary that contains evaluation metrics.\u001B[39;00m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    327\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msupport_quick_scoring:\n\u001B[0;32m--> 328\u001B[0m     _, group_labels, group_preds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_fast_eval\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    329\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnews_filename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbehaviors_file\u001B[49m\n\u001B[1;32m    330\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    331\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    332\u001B[0m     _, group_labels, group_preds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_slow_eval(\n\u001B[1;32m    333\u001B[0m         news_filename, behaviors_file\n\u001B[1;32m    334\u001B[0m     )\n",
      "File \u001B[0;32m~/gitLocal/recommenders/recommenders/models/newsrec/models/base_model.py:402\u001B[0m, in \u001B[0;36mBaseModel.run_fast_eval\u001B[0;34m(self, news_filename, behaviors_file)\u001B[0m\n\u001B[1;32m    400\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_fast_eval\u001B[39m(\u001B[38;5;28mself\u001B[39m, news_filename, behaviors_file):\n\u001B[1;32m    401\u001B[0m     news_vecs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_news(news_filename)\n\u001B[0;32m--> 402\u001B[0m     user_vecs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_user\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnews_filename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbehaviors_file\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    404\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnews_vecs \u001B[38;5;241m=\u001B[39m news_vecs\n\u001B[1;32m    405\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muser_vecs \u001B[38;5;241m=\u001B[39m user_vecs\n",
      "File \u001B[0;32m~/gitLocal/recommenders/recommenders/models/newsrec/models/base_model.py:361\u001B[0m, in \u001B[0;36mBaseModel.run_user\u001B[0;34m(self, news_filename, behaviors_file)\u001B[0m\n\u001B[1;32m    357\u001B[0m user_vecs \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    358\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch_data_input \u001B[38;5;129;01min\u001B[39;00m tqdm(\n\u001B[1;32m    359\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtest_iterator\u001B[38;5;241m.\u001B[39mload_user_from_file(news_filename, behaviors_file)\n\u001B[1;32m    360\u001B[0m ):\n\u001B[0;32m--> 361\u001B[0m     user_index, user_vec \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muser\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_data_input\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    362\u001B[0m     user_indexes\u001B[38;5;241m.\u001B[39mextend(np\u001B[38;5;241m.\u001B[39mreshape(user_index, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m    363\u001B[0m     user_vecs\u001B[38;5;241m.\u001B[39mextend(user_vec)\n",
      "File \u001B[0;32m~/gitLocal/recommenders/recommenders/models/newsrec/models/base_model.py:340\u001B[0m, in \u001B[0;36mBaseModel.user\u001B[0;34m(self, batch_user_input)\u001B[0m\n\u001B[1;32m    338\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21muser\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch_user_input):\n\u001B[1;32m    339\u001B[0m     user_input \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_user_feature_from_iter(batch_user_input)\n\u001B[0;32m--> 340\u001B[0m     user_vec \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muserencoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_on_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43muser_input\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    341\u001B[0m     user_index \u001B[38;5;241m=\u001B[39m batch_user_input[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimpr_index_batch\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    343\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m user_index, user_vec\n",
      "File \u001B[0;32m~/mambaforge/envs/reco_base/lib/python3.9/site-packages/keras/engine/training_v1.py:1321\u001B[0m, in \u001B[0;36mModel.predict_on_batch\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m   1318\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m(inputs)\n\u001B[1;32m   1320\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_predict_function()\n\u001B[0;32m-> 1321\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(outputs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   1324\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/mambaforge/envs/reco_base/lib/python3.9/site-packages/keras/backend.py:4608\u001B[0m, in \u001B[0;36mGraphExecutionFunction.__call__\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m   4598\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   4599\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_callable_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   4600\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m feed_arrays \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_feed_arrays\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4604\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m session \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_session\n\u001B[1;32m   4605\u001B[0m ):\n\u001B[1;32m   4606\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n\u001B[0;32m-> 4608\u001B[0m fetched \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_callable_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43marray_vals\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_metadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_metadata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4609\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_fetch_callbacks(fetched[\u001B[38;5;241m-\u001B[39m\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fetches) :])\n\u001B[1;32m   4610\u001B[0m output_structure \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mnest\u001B[38;5;241m.\u001B[39mpack_sequence_as(\n\u001B[1;32m   4611\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_outputs_structure,\n\u001B[1;32m   4612\u001B[0m     fetched[: \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutputs)],\n\u001B[1;32m   4613\u001B[0m     expand_composites\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m   4614\u001B[0m )\n",
      "File \u001B[0;32m~/mambaforge/envs/reco_base/lib/python3.9/site-packages/tensorflow/python/client/session.py:1481\u001B[0m, in \u001B[0;36mBaseSession._Callable.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1479\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1480\u001B[0m   run_metadata_ptr \u001B[38;5;241m=\u001B[39m tf_session\u001B[38;5;241m.\u001B[39mTF_NewBuffer() \u001B[38;5;28;01mif\u001B[39;00m run_metadata \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1481\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[43mtf_session\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTF_SessionRunCallable\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_session\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_session\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1482\u001B[0m \u001B[43m                                         \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1483\u001B[0m \u001B[43m                                         \u001B[49m\u001B[43mrun_metadata_ptr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1484\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m run_metadata:\n\u001B[1;32m   1485\u001B[0m     proto_data \u001B[38;5;241m=\u001B[39m tf_session\u001B[38;5;241m.\u001B[39mTF_GetBuffer(run_metadata_ptr)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "print('hi')\n",
    "print(model.run_eval(valid_news_file, valid_behaviors_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T18:06:21.449804Z",
     "end_time": "2023-04-05T18:06:21.451912Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-05T18:06:21.453172Z",
     "end_time": "2023-04-05T18:07:23.465342Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]2023-04-05 18:06:22.607186: W tensorflow/c/c_api.cc:300] Operation '{name:'loss/mul' id:2002 op device:{requested: '', assigned: ''} def:{{{node loss/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss/mul/x, loss/activation_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-04-05 18:06:22.660848: W tensorflow/c/c_api.cc:300] Operation '{name:'training/Adam/att_layer2_1/q/v/Assign' id:2812 op device:{requested: '', assigned: ''} def:{{{node training/Adam/att_layer2_1/q/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training/Adam/att_layer2_1/q/v, training/Adam/att_layer2_1/q/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "step 110 , total_loss: 1.5801, data_loss: 1.4646: : 110it [01:01,  1.79it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.fit(train_news_file, train_behaviors_file, valid_news_file, valid_behaviors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-05T17:40:33.642821Z",
     "end_time": "2023-04-05T17:41:02.464408Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "586it [00:05, 111.62it/s]\n",
      "119it [00:23,  5.06it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m<timed exec>:1\u001B[0m\n",
      "File \u001B[0;32m~/gitLocal/recommenders/recommenders/models/newsrec/models/base_model.py:328\u001B[0m, in \u001B[0;36mBaseModel.run_eval\u001B[0;34m(self, news_filename, behaviors_file)\u001B[0m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;124;03m\"\"\"Evaluate the given file and returns some evaluation metrics.\u001B[39;00m\n\u001B[1;32m    319\u001B[0m \n\u001B[1;32m    320\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    324\u001B[0m \u001B[38;5;124;03m    dict: A dictionary that contains evaluation metrics.\u001B[39;00m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    327\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msupport_quick_scoring:\n\u001B[0;32m--> 328\u001B[0m     _, group_labels, group_preds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_fast_eval\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    329\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnews_filename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbehaviors_file\u001B[49m\n\u001B[1;32m    330\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    331\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    332\u001B[0m     _, group_labels, group_preds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_slow_eval(\n\u001B[1;32m    333\u001B[0m         news_filename, behaviors_file\n\u001B[1;32m    334\u001B[0m     )\n",
      "File \u001B[0;32m~/gitLocal/recommenders/recommenders/models/newsrec/models/base_model.py:402\u001B[0m, in \u001B[0;36mBaseModel.run_fast_eval\u001B[0;34m(self, news_filename, behaviors_file)\u001B[0m\n\u001B[1;32m    400\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_fast_eval\u001B[39m(\u001B[38;5;28mself\u001B[39m, news_filename, behaviors_file):\n\u001B[1;32m    401\u001B[0m     news_vecs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_news(news_filename)\n\u001B[0;32m--> 402\u001B[0m     user_vecs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_user\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnews_filename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbehaviors_file\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    404\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnews_vecs \u001B[38;5;241m=\u001B[39m news_vecs\n\u001B[1;32m    405\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muser_vecs \u001B[38;5;241m=\u001B[39m user_vecs\n",
      "File \u001B[0;32m~/gitLocal/recommenders/recommenders/models/newsrec/models/base_model.py:361\u001B[0m, in \u001B[0;36mBaseModel.run_user\u001B[0;34m(self, news_filename, behaviors_file)\u001B[0m\n\u001B[1;32m    357\u001B[0m user_vecs \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    358\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch_data_input \u001B[38;5;129;01min\u001B[39;00m tqdm(\n\u001B[1;32m    359\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtest_iterator\u001B[38;5;241m.\u001B[39mload_user_from_file(news_filename, behaviors_file)\n\u001B[1;32m    360\u001B[0m ):\n\u001B[0;32m--> 361\u001B[0m     user_index, user_vec \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muser\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_data_input\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    362\u001B[0m     user_indexes\u001B[38;5;241m.\u001B[39mextend(np\u001B[38;5;241m.\u001B[39mreshape(user_index, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m    363\u001B[0m     user_vecs\u001B[38;5;241m.\u001B[39mextend(user_vec)\n",
      "File \u001B[0;32m~/gitLocal/recommenders/recommenders/models/newsrec/models/base_model.py:340\u001B[0m, in \u001B[0;36mBaseModel.user\u001B[0;34m(self, batch_user_input)\u001B[0m\n\u001B[1;32m    338\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21muser\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch_user_input):\n\u001B[1;32m    339\u001B[0m     user_input \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_user_feature_from_iter(batch_user_input)\n\u001B[0;32m--> 340\u001B[0m     user_vec \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muserencoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_on_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43muser_input\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    341\u001B[0m     user_index \u001B[38;5;241m=\u001B[39m batch_user_input[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimpr_index_batch\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    343\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m user_index, user_vec\n",
      "File \u001B[0;32m~/mambaforge/envs/reco_base/lib/python3.9/site-packages/keras/engine/training_v1.py:1321\u001B[0m, in \u001B[0;36mModel.predict_on_batch\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m   1318\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m(inputs)\n\u001B[1;32m   1320\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_predict_function()\n\u001B[0;32m-> 1321\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(outputs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   1324\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/mambaforge/envs/reco_base/lib/python3.9/site-packages/keras/backend.py:4608\u001B[0m, in \u001B[0;36mGraphExecutionFunction.__call__\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m   4598\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   4599\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_callable_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   4600\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m feed_arrays \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_feed_arrays\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4604\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m session \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_session\n\u001B[1;32m   4605\u001B[0m ):\n\u001B[1;32m   4606\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n\u001B[0;32m-> 4608\u001B[0m fetched \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_callable_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43marray_vals\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_metadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_metadata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4609\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_fetch_callbacks(fetched[\u001B[38;5;241m-\u001B[39m\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fetches) :])\n\u001B[1;32m   4610\u001B[0m output_structure \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mnest\u001B[38;5;241m.\u001B[39mpack_sequence_as(\n\u001B[1;32m   4611\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_outputs_structure,\n\u001B[1;32m   4612\u001B[0m     fetched[: \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutputs)],\n\u001B[1;32m   4613\u001B[0m     expand_composites\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m   4614\u001B[0m )\n",
      "File \u001B[0;32m~/mambaforge/envs/reco_base/lib/python3.9/site-packages/tensorflow/python/client/session.py:1481\u001B[0m, in \u001B[0;36mBaseSession._Callable.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1479\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1480\u001B[0m   run_metadata_ptr \u001B[38;5;241m=\u001B[39m tf_session\u001B[38;5;241m.\u001B[39mTF_NewBuffer() \u001B[38;5;28;01mif\u001B[39;00m run_metadata \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1481\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[43mtf_session\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTF_SessionRunCallable\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_session\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_session\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1482\u001B[0m \u001B[43m                                         \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1483\u001B[0m \u001B[43m                                         \u001B[49m\u001B[43mrun_metadata_ptr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1484\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m run_metadata:\n\u001B[1;32m   1485\u001B[0m     proto_data \u001B[38;5;241m=\u001B[39m tf_session\u001B[38;5;241m.\u001B[39mTF_GetBuffer(run_metadata_ptr)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res_syn = model.run_eval(valid_news_file, valid_behaviors_file)\n",
    "print(res_syn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res_syn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m sb\u001B[38;5;241m.\u001B[39mglue(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mres_syn\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[43mres_syn\u001B[49m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'res_syn' is not defined"
     ]
    }
   ],
   "source": [
    "sb.glue(\"res_syn\", res_syn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(data_path, \"model\")\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "model.model.save_weights(os.path.join(model_path, \"nrms_ckpt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Predcition File\n",
    "This code segment is used to generate the prediction.zip file, which is in the same format in [MIND Competition Submission Tutorial](https://competitions.codalab.org/competitions/24122#learn_the_details-submission-guidelines).\n",
    "\n",
    "Please change the `MIND_type` parameter to `large` if you want to submit your prediction to [MIND Competition](https://msnews.github.io/competition.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_impr_indexes, group_labels, group_preds = model.run_fast_eval(valid_news_file, valid_behaviors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path, 'prediction.txt'), 'w') as f:\n",
    "    for impr_index, preds in tqdm(zip(group_impr_indexes, group_preds)):\n",
    "        impr_index += 1\n",
    "        pred_rank = (np.argsort(np.argsort(preds)[::-1]) + 1).tolist()\n",
    "        pred_rank = '[' + ','.join([str(i) for i in pred_rank]) + ']'\n",
    "        f.write(' '.join([str(impr_index), pred_rank])+ '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = zipfile.ZipFile(os.path.join(data_path, 'prediction.zip'), 'w', zipfile.ZIP_DEFLATED)\n",
    "f.write(os.path.join(data_path, 'prediction.txt'), arcname='prediction.txt')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\\[1\\] Wu et al. \"Neural News Recommendation with Multi-Head Self-Attention.\" in Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<br>\n",
    "\\[2\\] Wu, Fangzhao, et al. \"MIND: A Large-scale Dataset for News Recommendation\" Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. https://msnews.github.io/competition.html <br>\n",
    "\\[3\\] GloVe: Global Vectors for Word Representation. https://nlp.stanford.edu/projects/glove/"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "3a9a0c422ff9f08d62211b9648017c63b0a26d2c935edc37ebb8453675d13bb5"
  },
  "kernelspec": {
   "name": "reco_base",
   "language": "python",
   "display_name": "Python 3.9.16 (reco_base)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
